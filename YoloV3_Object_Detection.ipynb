{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "784osbdWpCRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kv7geDRSQBgT"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import gradio as gr\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alpesTbVQ91M",
        "outputId": "66742040-f25b-4212-ddd5-698dbf7a50f8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO model\n",
        "yolo_config = \"/content/drive/My Drive/Object_Detection/yolov3.cfg\"\n",
        "yolo_weights = \"/content/drive/My Drive/Object_Detection/yolov3.weights\"\n",
        "yolo_classes = \"/content/drive/My Drive/Object_Detection/coco.names\""
      ],
      "metadata": {
        "id": "HfvWnQ-TRnZN"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load class labels\n",
        "with open(yolo_classes, \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]"
      ],
      "metadata": {
        "id": "_W7-l4y6R_ZN"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load YOLO model\n",
        "net = cv2.dnn.readNet(yolo_weights, yolo_config)\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]"
      ],
      "metadata": {
        "id": "nPE-4oh9SDek"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def detect_objects(image):\n",
        "    img = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # Convert from RGB to BGR (OpenCV format)\n",
        "    height, width, _ = img.shape\n",
        "\n",
        "    # Convert image to blob\n",
        "    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "    net.setInput(blob)\n",
        "    outs = net.forward(output_layers)\n",
        "\n",
        "    # Process detected objects\n",
        "    class_ids, confidences, boxes = [], [], []\n",
        "    for out in outs:\n",
        "        for detection in out:\n",
        "            scores = detection[5:]\n",
        "            class_id = np.argmax(scores)\n",
        "            confidence = scores[class_id]\n",
        "            if confidence > 0.5:\n",
        "                center_x, center_y, w, h = (detection[0:4] * [width, height, width, height]).astype(\"int\")\n",
        "                x = int(center_x - w / 2)\n",
        "                y = int(center_y - h / 2)\n",
        "                boxes.append([x, y, w, h])\n",
        "                confidences.append(float(confidence))\n",
        "                class_ids.append(class_id)\n",
        "\n",
        "    # Non-maximum suppression\n",
        "    indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "    colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "\n",
        "    # Draw bounding boxes\n",
        "    for i in indexes.flatten():\n",
        "        x, y, w, h = boxes[i]\n",
        "        label = f\"{classes[class_ids[i]]}: {confidences[i]:.2f}\"\n",
        "        color = colors[class_ids[i]]\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "        cv2.putText(img, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
        "\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert back to RGB\n",
        "    return img_rgb"
      ],
      "metadata": {
        "id": "ut9HP3DgSJFV"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio Interface\n",
        "demo = gr.Interface(\n",
        "                    fn=detect_objects,\n",
        "                    inputs=gr.Image(type=\"numpy\"),\n",
        "                    outputs=gr.Image(type=\"numpy\"),\n",
        "                    title=\"YOLO Object Detection\",\n",
        "                    description=\"Upload an image to detect objects using YOLO v3.\")\n",
        "demo.launch()"
      ],
      "metadata": {
        "id": "blqSWE1SYsg6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "595a7741-e344-49a7-9cb6-6e02510983da"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5aea42c57a4664b164.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5aea42c57a4664b164.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}